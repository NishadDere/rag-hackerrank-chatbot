ğŸš€ RAG Hackerrank Chatbot

A full Retrieval-Augmented Generation (RAG) system with conversational memory, strict/hybrid answer modes, citations, confidence scoring, chunk previews, reranking, and a simple FastAPI web UI.

This project demonstrates a complete end-to-end RAG pipeline, from document ingestion â†’ semantic chunking â†’ embeddings â†’ vector search â†’ reranking â†’ LLM answering with provenance â†’ frontend chat interface.

Perfect for learning, extending, or adapting into a personal AI assistant.

â­ Features
ğŸ” Retrieval & Ranking

ChromaDB persistent vector store

MPNet embeddings (768-dim) for high-quality retrieval

BGE Reranker for improved relevance ordering

Multi-query expansion for better recall

ğŸ§  Smart Answering (RAG)

Strict mode â†’ answer only from document (no hallucination)

Hybrid mode â†’ uses document first, but can extend with external knowledge

Citation support ([Chunk X])

Confidence scoring (based on retrieved chunks)

Chunk previews for transparency

ğŸ’¬ Conversation Features

ChatGPT-style typing animation

Multi-turn memory (configurable context window)

Local browser session memory

Per-session system prompt

Toggleable UI controls (mode, citations, previews, dark mode)

ğŸ“„ Document Support

Upload documents through /upload endpoint

Auto-save uploaded files

Future-ready pipeline for multi-document RAG

ğŸŒ Web Frontend

Clean minimal UI

Dark mode

Confidence bar

Chunk preview panel

Local session persistence

Built with pure HTML/CSS/JS (no build tools)

ğŸ— Project Structure
rag-hackerrank-chatbot/
â”‚
â”œâ”€â”€ app.py                     # FastAPI backend
â”œâ”€â”€ static/
â”‚     â””â”€â”€ index.html           # Web UI
â”‚
â”œâ”€â”€ code/
â”‚     â”œâ”€â”€ ingest_and_chunk.py
â”‚     â”œâ”€â”€ embed_chunks.py
â”‚     â”œâ”€â”€ index_chroma.py
â”‚     â”œâ”€â”€ retriever_chroma.py  # embeddings + reranker + multi-query
â”‚     â”œâ”€â”€ answer_with_provenance.py
â”‚     â””â”€â”€ chatbot.py           # CLI version
â”‚
â”œâ”€â”€ data/
â”‚     â””â”€â”€ hackerrank_doc.txt
â”‚
â”œâ”€â”€ chroma_db/                 # vector store (ignored in git)
â”œâ”€â”€ venv/                      # virtual environment (ignored)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ğŸ›  Installation
1. Clone
git clone https://github.com/NishadDere/rag-hackerrank-chatbot.git
cd rag-hackerrank-chatbot

2. Create virtual environment
python -m venv venv
venv\Scripts\activate  # on Windows

3. Install dependencies
pip install -r requirements.txt


(If no requirements.txt exists, generate one:)

pip freeze > requirements.txt

ğŸ” Environment Variables

Create a .env file in the root directory:

GROQ_API_KEY=your_api_key_here
GROQ_MODEL=llama-3.1-8b-instant


This is automatically loaded by dotenv.

ğŸ“¥ Prepare Your Document (RAG Pipeline)
Step 1 â€” Ingest & Chunk
python -m code.ingest_and_chunk

Step 2 â€” Embed
python -m code.embed_chunks

Step 3 â€” Index
python -m code.index_chroma

â–¶ Running the Backend Server
uvicorn app:app --reload


Backend should run at:

http://localhost:8000


Open the UI:

http://localhost:8000/static/index.html

ğŸ¨ Frontend UI Screenshots (Optional)

(You can add screenshots later here.)

ğŸ§ª CLI Version
python -m code.chatbot


Supports:

/mode strict|hybrid

/citations on|off

/preview on|off

chat history awareness

typing animation

ğŸ§© Future Roadmap

Multi-document RAG

Document search & filtering

Semantic highlighting of cited chunks

Chunk heatmap visualization

User accounts + cloud session persistence

Optional Postgres/MongoDB for chat logs

Switchable embeddings & reranker models

Streaming responses (SSE / WebSockets)
